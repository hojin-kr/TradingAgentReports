name: Post-process Investment Reports

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      date:
        description: 'Target date for processing reports (YYYY-MM-DD)'
        required: true
        type: string
      dry_run:
        description: 'Perform dry run (show what would be processed without processing)'
        required: false
        type: boolean
        default: false
      force:
        description: 'Force processing even if simplified files already exist'
        required: false
        type: boolean
        default: false

  # Automatic trigger when generate-reports workflow completes successfully
  workflow_run:
    workflows: ["Generate daily TradingAgents reports"]
    types: [completed]
    branches: [main]

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.10'

jobs:
  postprocess-reports:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Upgrade pip
      run: python -m pip install --upgrade pip

    - name: Install dependencies
      run: |
        python -m pip install -r requirements.txt
      continue-on-error: true
    
    - name: Determine target date
      id: date
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "TARGET_DATE=${{ inputs.date }}" >> $GITHUB_OUTPUT
          echo "DRY_RUN=${{ inputs.dry_run }}" >> $GITHUB_OUTPUT
          echo "FORCE=${{ inputs.force }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "workflow_run" ]; then
          # For workflow_run events, detect the date from the most recent reports directory
          echo "Detecting date from workflow_run trigger..."
          
          # Find the most recent reports directory
          LATEST_REPORTS_DIR=$(find reports -maxdepth 1 -type d -name "20*" | sort | tail -1)
          
          if [ -n "$LATEST_REPORTS_DIR" ]; then
            # Extract date from directory name (format: reports/YYYY-MM-DD)
            TARGET_DATE=$(basename "$LATEST_REPORTS_DIR")
            echo "Detected date from latest reports directory: $TARGET_DATE"
          else
            # Fallback to yesterday if no reports directory found
            TARGET_DATE=$(date -d 'yesterday' +%Y-%m-%d)
            echo "No reports directory found, using yesterday: $TARGET_DATE"
          fi
          
          echo "TARGET_DATE=$TARGET_DATE" >> $GITHUB_OUTPUT
          echo "DRY_RUN=false" >> $GITHUB_OUTPUT
          echo "FORCE=false" >> $GITHUB_OUTPUT
        else
          # For other events, use yesterday's date
          echo "TARGET_DATE=$(date -d 'yesterday' +%Y-%m-%d)" >> $GITHUB_OUTPUT
          echo "DRY_RUN=false" >> $GITHUB_OUTPUT
          echo "FORCE=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Validate template file
      run: |
        if [ ! -f "report_template.xml" ]; then
          echo "Error: report_template.xml not found"
          exit 1
        fi
        echo "Template file found and validated"
    
    - name: Check for reports to process
      id: check_reports
      run: |
        TARGET_DATE="${{ steps.date.outputs.TARGET_DATE }}"
        REPORTS_DIR="reports/$TARGET_DATE"
        
        echo "Checking for reports in directory: $REPORTS_DIR"
        echo "Target date: $TARGET_DATE"
        
        if [ ! -d "$REPORTS_DIR" ]; then
          echo "No reports directory found for date: $TARGET_DATE"
          echo "Available report directories:"
          ls -la reports/ || echo "No reports directory exists"
          echo "REPORTS_EXIST=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        FINAL_REPORTS=$(find "$REPORTS_DIR" -name "final_trade_decision.md" | wc -l)
        echo "Found $FINAL_REPORTS final trade decision reports for $TARGET_DATE"
        
        if [ "$FINAL_REPORTS" -eq 0 ]; then
          echo "REPORTS_EXIST=false" >> $GITHUB_OUTPUT
        else
          echo "REPORTS_EXIST=true" >> $GITHUB_OUTPUT
          echo "REPORT_COUNT=$FINAL_REPORTS" >> $GITHUB_OUTPUT
        fi
    
    - name: Run post-processing (dry run)
      if: steps.check_reports.outputs.REPORTS_EXIST == 'true' && steps.date.outputs.DRY_RUN == 'true'
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        # Ollama configuration
        COIN_LLM_PROVIDER: ollama
        TRADING_LLM_PROVIDER: ollama
        OLLAMA_BASE_URL: ${{ secrets.OLLAMA_BASE_URL }}
        OLLAMA_MODEL: llama3.2
      run: |
        echo "Running dry run for date: ${{ steps.date.outputs.TARGET_DATE }}"
        python postprocess_final_reports.py \
          --date "${{ steps.date.outputs.TARGET_DATE }}" \
          --dry-run
    
    - name: Run post-processing
      if: steps.check_reports.outputs.REPORTS_EXIST == 'true' && steps.date.outputs.DRY_RUN == 'false'
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        # Ollama configuration
        COIN_LLM_PROVIDER: ollama
        TRADING_LLM_PROVIDER: ollama
        OLLAMA_BASE_URL: ${{ secrets.OLLAMA_BASE_URL }}
        OLLAMA_MODEL: llama3.2
      run: |
        echo "Processing reports for date: ${{ steps.date.outputs.TARGET_DATE }}"
        FORCE_FLAG=""
        if [ "${{ steps.date.outputs.FORCE }}" = "true" ]; then
          FORCE_FLAG="--force"
          echo "Force processing enabled"
        fi
        python postprocess_final_reports.py \
          --date "${{ steps.date.outputs.TARGET_DATE }}" \
          $FORCE_FLAG
    
    - name: Commit and push simplified reports
      if: steps.check_reports.outputs.REPORTS_EXIST == 'true' && steps.date.outputs.DRY_RUN == 'false'
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git fetch origin
        BRANCH="${GITHUB_REF_NAME:-main}"
        git pull --rebase origin "$BRANCH" || true
        
        # Add simplified reports
        git add reports/${{ steps.date.outputs.TARGET_DATE }}/**/simplified_*.md || true
        
        # Check if there are changes to commit
        if ! git diff --cached --quiet; then
          git commit -m "Add simplified reports for ${{ steps.date.outputs.TARGET_DATE }}
          
          - Processed ${{ steps.check_reports.outputs.REPORT_COUNT }} final trade decision reports
          - Applied standardized template for general investor accessibility
          - Simplified technical language and removed complex strategies
          - Auto-generated by postprocess-reports workflow"
          
          git push || true
          echo "Successfully committed and pushed simplified reports"
        else
          echo "No simplified reports to commit"
        fi
    
    - name: Create summary
      if: always()
      run: |
        echo "## Post-processing Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Date**: ${{ steps.date.outputs.TARGET_DATE }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Mode**: ${{ steps.date.outputs.DRY_RUN == 'true' && 'Dry Run' || 'Full Processing' }}" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.check_reports.outputs.REPORTS_EXIST }}" = "true" ]; then
          echo "- **Reports Found**: ${{ steps.check_reports.outputs.REPORT_COUNT }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ✅ Processing completed" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Status**: ⚠️ No reports found for processing" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Files Processed" >> $GITHUB_STEP_SUMMARY
        if [ -d "reports/${{ steps.date.outputs.TARGET_DATE }}" ]; then
          find "reports/${{ steps.date.outputs.TARGET_DATE }}" -name "simplified_*.md" | while read file; do
            echo "- \`$file\`" >> $GITHUB_STEP_SUMMARY
          done
        fi

  # Optional: Run quality checks on simplified reports
  quality-check:
    runs-on: ubuntu-latest
    needs: postprocess-reports
    if: success()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install quality check dependencies
      run: |
        pip install textstat readability
    
    - name: Run readability analysis
      run: |
        python3 << 'EOF'
        import os
        import glob
        import textstat
        from pathlib import Path
        
        def analyze_readability(file_path):
            """Analyze readability of a markdown file."""
            try:
                content = Path(file_path).read_text(encoding='utf-8')
                
                # Remove markdown formatting for analysis
                import re
                clean_content = re.sub(r'[#*`\[\]()_-]', '', content)
                clean_content = re.sub(r'\n+', ' ', clean_content)
                
                if len(clean_content.strip()) < 50:  # Skip very short files
                    return None
                
                flesch_score = textstat.flesch_reading_ease(clean_content)
                grade_level = textstat.flesch_kincaid_grade(clean_content)
                
                return {
                    'file': file_path,
                    'flesch_score': flesch_score,
                    'grade_level': grade_level,
                    'word_count': len(clean_content.split())
                }
            except Exception as e:
                print(f"Error analyzing {file_path}: {e}")
                return None
        
        # Find simplified reports
        simplified_files = glob.glob('reports/**/simplified_*.md', recursive=True)
        
        if not simplified_files:
            print("No simplified reports found for quality analysis")
            exit(0)
        
        print("## Readability Analysis Results")
        print("| File | Flesch Score | Grade Level | Word Count | Assessment |")
        print("|------|-------------|-------------|------------|------------|")
        
        total_files = 0
        good_readability = 0
        
        for file_path in simplified_files:
            result = analyze_readability(file_path)
            if result:
                total_files += 1
                
                # Assess readability
                if result['flesch_score'] >= 60 and result['grade_level'] <= 12:
                    assessment = "✅ Good"
                    good_readability += 1
                elif result['flesch_score'] >= 30:
                    assessment = "⚠️ Acceptable"
                else:
                    assessment = "❌ Needs Improvement"
                
                print(f"| {result['file']} | {result['flesch_score']:.1f} | {result['grade_level']:.1f} | {result['word_count']} | {assessment} |")
        
        print(f"\n**Summary**: {good_readability}/{total_files} files have good readability")
        
        # Set output for GitHub Actions
        with open(os.environ['GITHUB_STEP_SUMMARY'], 'a') as f:
            f.write(f"\n## Readability Analysis\n")
            f.write(f"- **Files Analyzed**: {total_files}\n")
            f.write(f"- **Good Readability**: {good_readability}/{total_files}\n")
            f.write(f"- **Target**: Flesch Score ≥60, Grade Level ≤12\n")
        EOF